{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T12:38:01.593233Z",
     "iopub.status.busy": "2022-09-07T12:38:01.592370Z",
     "iopub.status.idle": "2022-09-07T12:39:27.023666Z",
     "shell.execute_reply": "2022-09-07T12:39:27.022857Z",
     "shell.execute_reply.started": "2022-09-07T12:38:01.593151Z"
    }
   },
   "outputs": [],
   "source": [
    "!sudo apt update && sudo apt upgrade -y && sudo apt install protobuf-compiler python3-dev python3-pip python-is-python3 -y\n",
    "!pip install --upgrade tensorflow-gpu numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T12:42:00.120069Z",
     "iopub.status.busy": "2022-09-07T12:42:00.119221Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.isdir(\"Tensorflow/models\"):\n",
    "    !cd Tensorflow && git clone https://github.com/tensorflow/models.git\n",
    "    \n",
    "!cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T13:02:50.712121Z",
     "iopub.status.busy": "2022-09-07T13:02:50.711399Z",
     "iopub.status.idle": "2022-09-07T13:02:50.717124Z",
     "shell.execute_reply": "2022-09-07T13:02:50.716171Z",
     "shell.execute_reply.started": "2022-09-07T13:02:50.712089Z"
    }
   },
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = \"Tensorflow/workspace\"\n",
    "SCRIPTS_PATH = \"Tensorflow/scripts\"\n",
    "APIMODEL_PATH = \"Tensorflow/models\"\n",
    "ANNOTATION_PATH = f\"{WORKSPACE_PATH}/annotations\"\n",
    "IMAGE_PATH = f\"{WORKSPACE_PATH}/images\"\n",
    "MODEL_PATH = f\"{WORKSPACE_PATH}/models\"\n",
    "PRETRAINED_MODEL_PATH = f\"{WORKSPACE_PATH}/pre-trained-models\"\n",
    "CUSTOM_MODEL_NAME = \"model\"\n",
    "CONFIG_PATH = f\"{MODEL_PATH}/{CUSTOM_MODEL_NAME}/pipeline.config\"\n",
    "CHECKPOINT_PATH = f\"{MODEL_PATH}/{CUSTOM_MODEL_NAME}/checkpoint\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-07T13:14:23.551007Z",
     "iopub.status.busy": "2022-09-07T13:14:23.550674Z",
     "iopub.status.idle": "2022-09-07T13:14:27.889805Z",
     "shell.execute_reply": "2022-09-07T13:14:27.888477Z",
     "shell.execute_reply.started": "2022-09-07T13:14:23.550980Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir {PRETRAINED_MODEL_PATH}/{CUSTOM_MODEL_NAME} && wget -O {PRETRAINED_MODEL_PATH}/{CUSTOM_MODEL_NAME}.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz && tar -xf {PRETRAINED_MODEL_PATH}/{CUSTOM_MODEL_NAME}.tar.gz -C {PRETRAINED_MODEL_PATH}/{CUSTOM_MODEL_NAME} --strip-components 1 && mkdir {MODEL_PATH}/{CUSTOM_MODEL_NAME}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the appropriate configuration file from ``Tensorflow/models/research/object_detection/configs/tf2/`` to ``Tensorflow/workspace/models/{CUSTOM_MODEL_NAME}/`` as ``pipeline.config``. It is important to copy the configuration file to the correct directory, otherwise the training will fail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Create Label Map and TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{\"name\": \"hoop\", \"id\": 1}]\n",
    "\n",
    "with open(ANNOTATION_PATH + \"/label_map.pbtxt\", \"w\") as f:\n",
    "    for label in labels:\n",
    "        f.write(\"item { \\n\")\n",
    "        f.write(f\"\\tname:'{label['name']}'\\n\")\n",
    "        f.write(f\"\\tid:{label['id']}\\n\")\n",
    "        f.write(\"}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {SCRIPTS_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/train'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/train.record'}\n",
    "!python {SCRIPTS_PATH + '/generate_tfrecord.py'} -x{IMAGE_PATH + '/test'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/test.record'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Update the Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(CONFIG_PATH, \"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str, pipeline_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = 1\n",
    "pipeline_config.train_config.batch_size = 16\n",
    "pipeline_config.train_config.fine_tune_checkpoint = (\n",
    "    f\"{PRETRAINED_MODEL_PATH}/{CUSTOM_MODEL_NAME}/checkpoint/ckpt-0\"\n",
    ")\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path = f\"{ANNOTATION_PATH}/label_map.pbtxt\"\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [\n",
    "    f\"{ANNOTATION_PATH}/train.record\"\n",
    "]\n",
    "pipeline_config.eval_input_reader[\n",
    "    0\n",
    "].label_map_path = f\"{ANNOTATION_PATH}/label_map.pbtxt\"\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [\n",
    "    f\"{ANNOTATION_PATH}/test.record\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "with tf.io.gfile.GFile(CONFIG_PATH, \"wb\") as f:\n",
    "    f.write(config_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"python {APIMODEL_PATH}/research/object_detection/model_main_tf2.py --model_dir={MODEL_PATH}/{CUSTOM_MODEL_NAME} --pipeline_config_path={MODEL_PATH}/{CUSTOM_MODEL_NAME}/pipeline.config --num_train_steps=30000\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6e7050dd1756071a800076127fc4a814278e292e1bdcd7f0eea1cdcb7332bee3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
